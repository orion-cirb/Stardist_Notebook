{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In case of problems or questions, please first check the list of [Frequently Asked Questions (FAQ)](https://stardist.net/docs/faq.html).**\n",
    "\n",
    "Please shutdown all other training/prediction notebooks before running this notebook (as those might occupy the GPU memory otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_857121/224698455.py:5: MatplotlibDeprecationWarning: Support for setting an rcParam that expects a str value to a non-str value is deprecated since 3.5 and support will be removed two minor releases later.\n",
      "  matplotlib.rcParams[\"image.interpolation\"] = None\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = None\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, normalize\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "\n",
    "from stardist import random_label_cmap, _draw_polygons, export_imagej_rois\n",
    "from stardist.models import StarDist2D\n",
    "\n",
    "np.random.seed(6)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA memory released: GPU0\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "print('CUDA memory released: GPU0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We assume that data has already been downloaded in via notebook [1_data.ipynb](1_data.ipynb).  \n",
    "We now load images from the sub-folder `test` that have not been used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sorted(glob('/home/phm/Images/TrainingFoci/RNA/Images/ground_truth/test/*.tif'))\n",
    "X = list(map(imread,X))\n",
    "\n",
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "axis_norm = (0,1)   # normalize channels independently\n",
    "# axis_norm = (0,1,2) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all test images\n",
    "if False:\n",
    "    fig, ax = plt.subplots(7,8, figsize=(16,16))\n",
    "    for i,(a,x) in enumerate(zip(ax.flat, X)):\n",
    "        a.imshow(x if x.ndim==2 else x[...,0], cmap='gray')\n",
    "        a.set_title(i)\n",
    "    [a.axis('off') for a in ax.flat]\n",
    "    plt.tight_layout()\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model\n",
    "\n",
    "If you trained your own StarDist model (and optimized its thresholds) via notebook [2_training.ipynb](2_training.ipynb), then please set `demo_model = False` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 09:53:47.755537: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-05 09:53:48.681270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 191 MB memory:  -> device: 0, name: Quadro P4000, pci bus id: 0000:9e:00.0, compute capability: 6.1\n",
      "2023-01-05 09:53:48.689626: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 191.19M (200474624 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-05 09:53:48.690168: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 172.07M (180427264 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.474755, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "demo_model = False\n",
    "\n",
    "if demo_model:\n",
    "    print (\n",
    "        \"NOTE: This is loading a previously trained demo model!\\n\"\n",
    "        \"      Please set the variable 'demo_model = False' to load your own trained model.\",\n",
    "        file=sys.stderr, flush=True\n",
    "    )\n",
    "    model = StarDist2D.from_pretrained('2D_demo')\n",
    "else:\n",
    "    model = StarDist2D(None, name='fociRNA-1.2', basedir='/home/phm/Developpement/StarDist_Models/2D')\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Make sure to normalize the input image beforehand or supply a `normalizer` to the prediction function.\n",
    "\n",
    "Calling `model.predict_instances` will\n",
    "- predict object probabilities and star-convex polygon distances (see `model.predict` if you want those)\n",
    "- perform non-maximum suppression (with overlap threshold `nms_thresh`) for polygons above object probability threshold `prob_thresh`.\n",
    "- render all remaining polygon instances in a label image\n",
    "- return the label instances image and also the details (coordinates, etc.) of all remaining polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 09:53:59.363754: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 512.00MiB (rounded to 536870912)requested by op model/conv2d/Conv2D\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-01-05 09:53:59.363845: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for GPU_0_bfc\n",
      "2023-01-05 09:53:59.363880: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 38, Chunks in use: 38. 9.5KiB allocated for chunks. 9.5KiB in use in bin. 2.1KiB client-requested in use in bin.\n",
      "2023-01-05 09:53:59.363909: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 6, Chunks in use: 6. 3.0KiB allocated for chunks. 3.0KiB in use in bin. 3.0KiB client-requested in use in bin.\n",
      "2023-01-05 09:53:59.363931: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 3, Chunks in use: 3. 3.5KiB allocated for chunks. 3.5KiB in use in bin. 3.1KiB client-requested in use in bin.\n",
      "2023-01-05 09:53:59.363954: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-05 09:53:59.363975: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-05 09:53:59.363996: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364021: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 3, Chunks in use: 1. 53.2KiB allocated for chunks. 16.0KiB in use in bin. 16.0KiB client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364046: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 5, Chunks in use: 4. 194.2KiB allocated for chunks. 158.0KiB in use in bin. 144.0KiB client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364070: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 3, Chunks in use: 3. 246.2KiB allocated for chunks. 246.2KiB in use in bin. 216.0KiB client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364094: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 2, Chunks in use: 2. 396.0KiB allocated for chunks. 396.0KiB in use in bin. 288.0KiB client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364118: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 3, Chunks in use: 3. 1008.0KiB allocated for chunks. 1008.0KiB in use in bin. 864.0KiB client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364142: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 1, Chunks in use: 1. 576.0KiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364165: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 5, Chunks in use: 3. 6.19MiB allocated for chunks. 3.94MiB in use in bin. 3.38MiB client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364185: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364205: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364225: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364248: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 2. 32.00MiB allocated for chunks. 32.00MiB in use in bin. 32.00MiB client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364269: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364291: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 0. 114.24MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364314: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364334: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-05 09:53:59.364357: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 512.00MiB was 256.00MiB, Chunk State: \n",
      "2023-01-05 09:53:59.364376: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 162384640\n",
      "2023-01-05 09:53:59.364403: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56000000 of size 1280 next 1\n",
      "2023-01-05 09:53:59.364423: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56000500 of size 256 next 2\n",
      "2023-01-05 09:53:59.364441: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56000600 of size 256 next 3\n",
      "2023-01-05 09:53:59.364458: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56000700 of size 256 next 4\n",
      "2023-01-05 09:53:59.364475: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56000800 of size 256 next 5\n",
      "2023-01-05 09:53:59.364492: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56000900 of size 256 next 8\n",
      "2023-01-05 09:53:59.364509: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56000a00 of size 256 next 9\n",
      "2023-01-05 09:53:59.364526: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56000b00 of size 256 next 10\n",
      "2023-01-05 09:53:59.364543: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56000c00 of size 256 next 13\n",
      "2023-01-05 09:53:59.364560: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56000d00 of size 256 next 15\n",
      "2023-01-05 09:53:59.364577: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56000e00 of size 256 next 17\n",
      "2023-01-05 09:53:59.364594: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56000f00 of size 256 next 18\n",
      "2023-01-05 09:53:59.364611: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56001000 of size 256 next 21\n",
      "2023-01-05 09:53:59.364628: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56001100 of size 256 next 6\n",
      "2023-01-05 09:53:59.364645: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56001200 of size 256 next 70\n",
      "2023-01-05 09:53:59.364664: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56001300 of size 512 next 24\n",
      "2023-01-05 09:53:59.364681: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56001500 of size 512 next 7\n",
      "2023-01-05 09:53:59.364698: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56001700 of size 256 next 22\n",
      "2023-01-05 09:53:59.364715: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56001800 of size 256 next 23\n",
      "2023-01-05 09:53:59.364733: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56001900 of size 256 next 26\n",
      "2023-01-05 09:53:59.364750: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56001a00 of size 256 next 27\n",
      "2023-01-05 09:53:59.364767: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56001b00 of size 512 next 30\n",
      "2023-01-05 09:53:59.364784: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56001d00 of size 256 next 31\n",
      "2023-01-05 09:53:59.364801: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56001e00 of size 256 next 32\n",
      "2023-01-05 09:53:59.364818: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56001f00 of size 512 next 33\n",
      "2023-01-05 09:53:59.364835: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56002100 of size 256 next 36\n",
      "2023-01-05 09:53:59.364854: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56002200 of size 256 next 37\n",
      "2023-01-05 09:53:59.364872: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56002300 of size 256 next 44\n",
      "2023-01-05 09:53:59.364889: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56002400 of size 256 next 50\n",
      "2023-01-05 09:53:59.364906: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56002500 of size 256 next 48\n",
      "2023-01-05 09:53:59.364923: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56002600 of size 256 next 42\n",
      "2023-01-05 09:53:59.364941: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56002700 of size 512 next 59\n",
      "2023-01-05 09:53:59.364958: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56002900 of size 256 next 16\n",
      "2023-01-05 09:53:59.364975: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f7c56002a00 of size 17664 next 68\n",
      "2023-01-05 09:53:59.364993: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56006f00 of size 51200 next 12\n",
      "2023-01-05 09:53:59.365011: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56013700 of size 36864 next 11\n",
      "2023-01-05 09:53:59.365029: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5601c700 of size 36864 next 14\n",
      "2023-01-05 09:53:59.365047: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56025700 of size 184320 next 19\n",
      "2023-01-05 09:53:59.365064: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f7c56052700 of size 37120 next 54\n",
      "2023-01-05 09:53:59.365082: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605b800 of size 256 next 56\n",
      "2023-01-05 09:53:59.365099: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605b900 of size 256 next 57\n",
      "2023-01-05 09:53:59.365116: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605ba00 of size 512 next 58\n",
      "2023-01-05 09:53:59.365133: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605bc00 of size 256 next 60\n",
      "2023-01-05 09:53:59.365150: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605bd00 of size 256 next 61\n",
      "2023-01-05 09:53:59.365167: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605be00 of size 256 next 62\n",
      "2023-01-05 09:53:59.365184: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605bf00 of size 256 next 63\n",
      "2023-01-05 09:53:59.365201: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605c000 of size 256 next 66\n",
      "2023-01-05 09:53:59.365218: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605c100 of size 256 next 67\n",
      "2023-01-05 09:53:59.365235: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605c200 of size 256 next 64\n",
      "2023-01-05 09:53:59.365252: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605c300 of size 256 next 55\n",
      "2023-01-05 09:53:59.365269: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605c400 of size 256 next 65\n",
      "2023-01-05 09:53:59.365287: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605c500 of size 1280 next 69\n",
      "2023-01-05 09:53:59.365305: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605ca00 of size 1024 next 39\n",
      "2023-01-05 09:53:59.365332: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5605ce00 of size 104704 next 49\n",
      "2023-01-05 09:53:59.365351: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56076700 of size 36864 next 51\n",
      "2023-01-05 09:53:59.365369: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5607f700 of size 16384 next 40\n",
      "2023-01-05 09:53:59.365386: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f7c56083700 of size 20480 next 52\n",
      "2023-01-05 09:53:59.365404: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56088700 of size 73728 next 25\n",
      "2023-01-05 09:53:59.365423: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5609a700 of size 442368 next 29\n",
      "2023-01-05 09:53:59.365441: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56106700 of size 294912 next 28\n",
      "2023-01-05 09:53:59.365458: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5614e700 of size 294912 next 45\n",
      "2023-01-05 09:53:59.365476: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c56196700 of size 73728 next 46\n",
      "2023-01-05 09:53:59.365494: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c561a8700 of size 221184 next 47\n",
      "2023-01-05 09:53:59.365537: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f7c561de700 of size 1179648 next 34\n",
      "2023-01-05 09:53:59.365555: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c562fe700 of size 589824 next 20\n",
      "2023-01-05 09:53:59.365573: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5638e700 of size 1769472 next 38\n",
      "2023-01-05 09:53:59.365591: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5653e700 of size 1179648 next 41\n",
      "2023-01-05 09:53:59.365609: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f7c5665e700 of size 1179648 next 43\n",
      "2023-01-05 09:53:59.365627: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5677e700 of size 1179648 next 35\n",
      "2023-01-05 09:53:59.365645: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5689e700 of size 16777216 next 53\n",
      "2023-01-05 09:53:59.365663: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7c5789e700 of size 16777216 next 71\n",
      "2023-01-05 09:53:59.365681: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f7c5889e700 of size 119792640 next 18446744073709551615\n",
      "2023-01-05 09:53:59.365699: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
      "2023-01-05 09:53:59.365721: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 38 Chunks of size 256 totalling 9.5KiB\n",
      "2023-01-05 09:53:59.365742: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 6 Chunks of size 512 totalling 3.0KiB\n",
      "2023-01-05 09:53:59.365762: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1024 totalling 1.0KiB\n",
      "2023-01-05 09:53:59.365782: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 1280 totalling 2.5KiB\n",
      "2023-01-05 09:53:59.365802: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 16384 totalling 16.0KiB\n",
      "2023-01-05 09:53:59.365823: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 3 Chunks of size 36864 totalling 108.0KiB\n",
      "2023-01-05 09:53:59.365843: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 51200 totalling 50.0KiB\n",
      "2023-01-05 09:53:59.365863: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 73728 totalling 144.0KiB\n",
      "2023-01-05 09:53:59.365884: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 104704 totalling 102.2KiB\n",
      "2023-01-05 09:53:59.365904: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 184320 totalling 180.0KiB\n",
      "2023-01-05 09:53:59.365924: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 221184 totalling 216.0KiB\n",
      "2023-01-05 09:53:59.365944: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 294912 totalling 576.0KiB\n",
      "2023-01-05 09:53:59.365964: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 442368 totalling 432.0KiB\n",
      "2023-01-05 09:53:59.365984: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 589824 totalling 576.0KiB\n",
      "2023-01-05 09:53:59.366004: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 1179648 totalling 2.25MiB\n",
      "2023-01-05 09:53:59.366023: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1769472 totalling 1.69MiB\n",
      "2023-01-05 09:53:59.366043: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 16777216 totalling 32.00MiB\n",
      "2023-01-05 09:53:59.366065: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 38.30MiB\n",
      "2023-01-05 09:53:59.366084: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 162384640 memory_limit_: 200474624 available bytes: 38089984 curr_region_allocation_bytes_: 400949248\n",
      "2023-01-05 09:53:59.366112: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
      "Limit:                       200474624\n",
      "InUse:                        40157440\n",
      "MaxInUse:                     40157440\n",
      "NumAllocs:                         161\n",
      "MaxAllocSize:                 16777216\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-01-05 09:53:59.366147: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ***************************_________________________________________________________________________\n",
      "2023-01-05 09:53:59.368879: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:685 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[1,32,2048,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv2d/Conv2D' defined at (most recent call last):\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_857121/710589410.py\", line 2, in <module>\n      labels, details = model.predict_instances(img)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/stardist/models/base.py\", line 775, in predict_instances\n      for r in self._predict_instances_generator(*args, **kwargs):\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/stardist/models/base.py\", line 727, in _predict_instances_generator\n      for res in self._predict_sparse_generator(img, axes=axes, normalizer=normalizer, n_tiles=n_tiles,\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/stardist/models/base.py\", line 590, in _predict_sparse_generator\n      results = predict_direct(x)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/stardist/models/base.py\", line 398, in predict_direct\n      ys = self.keras_model.predict(x[np.newaxis], **predict_kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 225, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv2d/Conv2D'\nOOM when allocating tensor with shape[1,32,2048,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2d/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_767]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m normalize(X[\u001b[38;5;241m5\u001b[39m], \u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m99.8\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis_norm)\n\u001b[0;32m----> 2\u001b[0m labels, details \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/stardist/models/base.py:775\u001b[0m, in \u001b[0;36mStarDistBase.predict_instances\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(_predict_instances_generator)\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_instances\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;66;03m# the reason why the actual computation happens as a generator function\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    772\u001b[0m \n\u001b[1;32m    773\u001b[0m     \u001b[38;5;66;03m# return last \"yield\"ed value of generator\u001b[39;00m\n\u001b[1;32m    774\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 775\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_instances_generator(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    776\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/stardist/models/base.py:727\u001b[0m, in \u001b[0;36mStarDistBase._predict_instances_generator\u001b[0;34m(self, img, axes, normalizer, sparse, prob_thresh, nms_thresh, scale, n_tiles, show_tile_progress, verbose, return_labels, predict_kwargs, nms_kwargs, overlap_label, return_predict)\u001b[0m\n\u001b[1;32m    725\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse:\n\u001b[0;32m--> 727\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_sparse_generator(img, axes\u001b[38;5;241m=\u001b[39maxes, normalizer\u001b[38;5;241m=\u001b[39mnormalizer, n_tiles\u001b[38;5;241m=\u001b[39mn_tiles,\n\u001b[1;32m    728\u001b[0m                                               prob_thresh\u001b[38;5;241m=\u001b[39mprob_thresh, show_tile_progress\u001b[38;5;241m=\u001b[39mshow_tile_progress, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_kwargs):\n\u001b[1;32m    729\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    730\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtile\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# yield 'tile' each time a tile has been processed\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/stardist/models/base.py:590\u001b[0m, in \u001b[0;36mStarDistBase._predict_sparse_generator\u001b[0;34m(self, img, prob_thresh, axes, normalizer, n_tiles, show_tile_progress, b, **predict_kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m  \u001b[38;5;66;03m# yield None after each processed tile\u001b[39;00m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;66;03m# predict_direct -> prob, dist, [prob_class if multi_class]\u001b[39;00m\n\u001b[0;32m--> 590\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_direct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m     prob, dist \u001b[38;5;241m=\u001b[39m results[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    592\u001b[0m     prob, dist \u001b[38;5;241m=\u001b[39m _prep(prob, dist)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/stardist/models/base.py:398\u001b[0m, in \u001b[0;36mStarDistBase._predict_setup.<locals>.predict_direct\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_direct\u001b[39m(x):\n\u001b[0;32m--> 398\u001b[0m     ys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(y[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv2d/Conv2D' defined at (most recent call last):\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_857121/710589410.py\", line 2, in <module>\n      labels, details = model.predict_instances(img)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/stardist/models/base.py\", line 775, in predict_instances\n      for r in self._predict_instances_generator(*args, **kwargs):\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/stardist/models/base.py\", line 727, in _predict_instances_generator\n      for res in self._predict_sparse_generator(img, axes=axes, normalizer=normalizer, n_tiles=n_tiles,\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/stardist/models/base.py\", line 590, in _predict_sparse_generator\n      results = predict_direct(x)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/stardist/models/base.py\", line 398, in predict_direct\n      ys = self.keras_model.predict(x[np.newaxis], **predict_kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/opt/miniconda3/envs/stardist/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 225, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv2d/Conv2D'\nOOM when allocating tensor with shape[1,32,2048,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2d/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_767]"
     ]
    }
   ],
   "source": [
    "img = normalize(X[5], 1,99.8, axis=axis_norm)\n",
    "labels, details = model.predict_instances(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img if img.ndim==2 else img[...,0], clim=(0,1), cmap='gray')\n",
    "plt.imshow(labels, cmap=lbl_cmap, alpha=0.5)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions\n",
    "\n",
    "Uncomment the lines in the following cell if you want to save the example image and the predictions to disk.  \n",
    "See [this notebook](../other2D/export_imagej_rois.ipynb) for more details on how to export ImageJ ROIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tiff_imagej_compatible('example_image.tif', img, axes='YX')\n",
    "save_tiff_imagej_compatible('example_labels.tif', labels, axes='YX')\n",
    "#export_imagej_rois('example_rois.zip', details['coord'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example(model, i, show_dist=True):\n",
    "    img = normalize(X[i], 1,99.8, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img)\n",
    "\n",
    "    plt.figure(figsize=(13,10))\n",
    "    img_show = img if img.ndim==2 else img[...,0]\n",
    "    coord, points, prob = details['coord'], details['points'], details['prob']\n",
    "    plt.subplot(121); plt.imshow(img_show, cmap='gray'); plt.axis('off')\n",
    "    a = plt.axis()\n",
    "    _draw_polygons(coord, points, prob, show_dist=show_dist)\n",
    "    plt.axis(a)\n",
    "    plt.subplot(122); plt.imshow(img_show, cmap='gray'); plt.axis('off')\n",
    "    plt.imshow(labels, cmap=lbl_cmap, alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example(model, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example(model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example(model,5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paper = StarDist2D.from_pretrained('2D_paper_dsb2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example(model_paper, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versatile model\n",
    "\n",
    "Try this model first if you have images that look similar to the training data in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_versatile = StarDist2D.from_pretrained('2D_versatile_fluo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example(model_versatile, 2, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all available pretrained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StarDist2D.from_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
